{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b12edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 12:16:43.139259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 12:16:43.338392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-18 12:16:43.338409: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-18 12:16:44.087969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-18 12:16:44.088024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-18 12:16:44.088030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-18 12:16:45.125838: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-18 12:16:45.126041: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-18 12:16:45.126055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (poonia-HP-ProDesk-600-G6-Microtower-PC): /proc/driver/nvidia/version does not exist\n",
      "2023-01-18 12:16:45.126893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import StellarGraph\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9e891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(prop, value):\n",
    "    malware = {}\n",
    "    exe_files = []\n",
    "    for i in glob.glob('/home/poonia/Documents/opcode_dataset/dataset/PE/'+prop+'/*.exe'):\n",
    "        if(prop == 'malicious'):\n",
    "            exe_files.append(i.split('/')[-1].replace('.exe', '_malicious.exe'))\n",
    "            f_hash = i.split('/')[-1].split('.')[0]\n",
    "            malware[f_hash] = {}\n",
    "            malware[f_hash]['value'] = value\n",
    "        else:\n",
    "            exe_files.append(i.split('/')[-1])\n",
    "            f_hash = i.split('/')[-1].split('_')[0]\n",
    "            malware[f_hash] = {}\n",
    "            malware[f_hash]['value'] = value\n",
    "    edges_files = []\n",
    "    for i in glob.glob('/home/poonia/Documents/opcode_dataset/dataset/PE/'+prop+'/*.edge'):\n",
    "        edges_files.append(i.split('/')[-1])\n",
    "        f_hash = i.split('/')[-1].split('_')[0]\n",
    "        malware[f_hash]['edges'] = i.split('/')[-1]\n",
    "    node_files = []\n",
    "    for i in glob.glob('/home/poonia/Documents/opcode_dataset/dataset/PE/'+prop+'/*.json'):\n",
    "        node_files.append(i.split('/')[-1])\n",
    "        f_hash = i.split('/')[-1].split('_')[0]\n",
    "        malware[f_hash]['nodes']=i.split('/')[-1]\n",
    "    opcode_seq_files = []\n",
    "    for i in glob.glob('/home/poonia/Documents/opcode_dataset/dataset/PE/'+prop+'/*.opcode_seq'):\n",
    "        opcode_seq_files.append(i.split('/')[-1])\n",
    "        f_hash = i.split('/')[-1].split('_')[0]\n",
    "        malware[f_hash]['opcode_seq'] = i.split('/')[-1]\n",
    "    return malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b7dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_conversion(node_file):\n",
    "    data = pd.read_json(node_file)\n",
    "    np_data = np.array(data)\n",
    "    np_data_transpose = np_data.transpose()\n",
    "    df = pd.DataFrame(np_data_transpose, columns=['dest', 'src'])\n",
    "    one_hot_encoding = pd.get_dummies(df, columns=['dest', 'src'])\n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f919b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename, prop):\n",
    "    edges_file = 'dataset/PE/'+prop+'/'+filename['edges'].strip()\n",
    "    opcode_seq = 'dataset/PE/'+prop+'/'+filename['opcode_seq'].strip()\n",
    "    nodes_file = 'dataset/PE/'+prop+'/'+filename['nodes'].strip()\n",
    "    edges_from = []\n",
    "    edges_to = []\n",
    "    weights = []\n",
    "\n",
    "    with open(edges_file, 'r') as f:\n",
    "        edges = f.readlines()\n",
    "        for edge in edges:\n",
    "            tmp = edge.strip().split()\n",
    "            t = tmp[0].strip().split('->')\n",
    "            edges_from.append(t[0])\n",
    "            edges_to.append(t[1])\n",
    "            weights.append(tmp[1])\n",
    "    g_edges = pd.DataFrame({\"source\":edges_from, \"target\":edges_to, \"weights\":weights})\n",
    "    \n",
    "    with open('node_feature_mapping.json', 'r') as f:\n",
    "        operands = json.load(f)\n",
    "    \n",
    "    with open(nodes_file, 'r') as f:\n",
    "        node_feature = json.load(f)\n",
    "    #Nodes\n",
    "    index = []\n",
    "    dest = []\n",
    "    src = []\n",
    "    for node in node_feature:\n",
    "        index.append(node)\n",
    "        if(operands[node_feature[node]['dest']] == 0):\n",
    "            dest.append(0)\n",
    "        else:\n",
    "            dest.append(1)\n",
    "        if(operands[node_feature[node]['src']] == 0):\n",
    "            src.append(0)\n",
    "        else:\n",
    "            src.append(1)\n",
    "\n",
    "    g_nodes = pd.DataFrame({\"dest\":dest, \"src\":src}, index=index)\n",
    "    #g_nodes = pd.DataFrame(node_conversion(nodes_file), index=index)\n",
    "    #print(g_nodes)\n",
    "    G = StellarGraph(g_nodes, g_edges)\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bed29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(files, hash_to_num):\n",
    "    graph = {}\n",
    "    prop = ''\n",
    "    for i in files:\n",
    "        if(files[i]['value'] == 1):\n",
    "            prop = 'malicious'\n",
    "        else:\n",
    "            prop = 'benign'\n",
    "        g = load(files[i], prop)\n",
    "        graph[hash_to_num[str(i)]] = []\n",
    "        graph[hash_to_num[str(i)]].append(g)\n",
    "     \n",
    "    return graph\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987a29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "malware = read_files('malicious', 1)\n",
    "benign = read_files('benign', 0)\n",
    "dic = {}\n",
    "#dic.update(dict(itertools.islice(malware.items(), 10000)))\n",
    "#dic.update(benign)\n",
    "dic.update(dict(itertools.islice(malware.items(), 1500)))\n",
    "dic.update(dict(itertools.islice(benign.items(), 1500)))\n",
    "l = list(dic.items())\n",
    "random.shuffle(l)\n",
    "dic = dict(l)\n",
    "print(len(dic))\n",
    "d = {}\n",
    "hash_to_num = {}\n",
    "count = 0\n",
    "for i in dic:\n",
    "    if(dic[i]['value'] == 1):\n",
    "        d[str(count)] = 1\n",
    "        hash_to_num[str(i)] = str(count)\n",
    "    else:\n",
    "        d[str(count)] = 0\n",
    "        hash_to_num[str(i)] = str(count)\n",
    "    count+=1\n",
    "        \n",
    "\n",
    "df = pd.DataFrame([d])\n",
    "a = np.array(df)\n",
    "t = a.transpose()\n",
    "f_df = pd.DataFrame(t, columns=['Labels'])\n",
    "labels = pd.get_dummies(f_df, columns=['Labels'])\n",
    "labels.head()\n",
    "    \n",
    "graph_ref = dataset(dic, hash_to_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b56191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Labels\n",
      "1878       0\n",
      "2569       0\n",
      "672        1\n",
      "1893       0\n",
      "2544       0\n",
      "...      ...\n",
      "2864       1\n",
      "877        1\n",
      "1447       1\n",
      "80         1\n",
      "1741       1\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#d = pd.DataFrame(graph_ref, columns=['Graph', 'Labels'])\n",
    "from sklearn import model_selection\n",
    "\n",
    "graph_labels = f_df\n",
    "train_graphs, test_graphs = model_selection.train_test_split(\n",
    "    graph_labels, train_size=0.9, test_size=None, stratify=graph_labels,\n",
    ")\n",
    "print(test_graphs)\n",
    "\n",
    "graphs = []\n",
    "for i in graph_ref:\n",
    "    graphs.append(graph_ref[i][0])\n",
    "generator = PaddedGraphGenerator(graphs=graphs)\n",
    "#graph_list = list(graph_ref.values())\n",
    "#graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "105c9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01b569f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(generator.node_features_size)\n",
    "k = 35  # the number of rows for the output tensor\n",
    "layer_sizes = [32, 32, 32, 1]\n",
    "\n",
    "dgcnn_model = DeepGraphCNN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
    "    generator=generator,\n",
    "    k=k\n",
    ")\n",
    "x_inp, x_out = dgcnn_model.in_out_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4cf7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
    "x_out = MaxPool1D(pool_size=2)(x_out)\n",
    "\n",
    "x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
    "\n",
    "x_out = Flatten()(x_out)\n",
    "\n",
    "x_out = Dense(units=128, activation=\"relu\")(x_out)\n",
    "x_out = Dropout(rate=0.5)(x_out)\n",
    "\n",
    "predictions = Dense(units=1, activation=\"sigmoid\")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dae7b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=x_inp, outputs=predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001), loss=binary_crossentropy, metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4531a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = f_df\n",
    "train_graphs, test_graphs = model_selection.train_test_split(\n",
    "    graph_labels, train_size=0.9, test_size=None, stratify=graph_labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c4e68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = PaddedGraphGenerator(graphs=graphs)\n",
    "train_gen = gen.flow(\n",
    "    list(train_graphs.index - 1),\n",
    "    targets=train_graphs.values,\n",
    "    batch_size=50,\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "\n",
    "test_gen = gen.flow(\n",
    "    list(test_graphs.index - 1),\n",
    "    targets=test_graphs.values,\n",
    "    batch_size=1,\n",
    "    symmetric_normalization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418d1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dea3a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 40.2 GiB for an array with shape (73492, 73492) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/mapper/padded_graph_generator.py:326\u001b[0m, in \u001b[0;36mPaddedGraphSequence.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     graph_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[batch_start:batch_end]\n\u001b[0;32m--> 326\u001b[0m padded \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pad_graphs(g, adj, max_nodes) \u001b[38;5;28;01mfor\u001b[39;00m g, adj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(graphs, adj_graphs)\n\u001b[1;32m    328\u001b[0m ]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [output \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m padded \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m arrays], graph_targets\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/mapper/padded_graph_generator.py:327\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     graph_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[batch_start:batch_end]\n\u001b[1;32m    326\u001b[0m padded \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g, adj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(graphs, adj_graphs)\n\u001b[1;32m    328\u001b[0m ]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [output \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m padded \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m arrays], graph_targets\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/mapper/padded_graph_generator.py:291\u001b[0m, in \u001b[0;36mPaddedGraphSequence._pad_graphs\u001b[0;34m(self, graphs, adj_graphs, max_nodes)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adj_graphs:\n\u001b[1;32m    290\u001b[0m     adj\u001b[38;5;241m.\u001b[39mresize((max_nodes, max_nodes))\n\u001b[0;32m--> 291\u001b[0m adj_graphs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([adj\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adj_graphs])\n\u001b[1;32m    293\u001b[0m masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mlen\u001b[39m(graphs), max_nodes), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, graph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graphs):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/mapper/padded_graph_generator.py:291\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adj_graphs:\n\u001b[1;32m    290\u001b[0m     adj\u001b[38;5;241m.\u001b[39mresize((max_nodes, max_nodes))\n\u001b[0;32m--> 291\u001b[0m adj_graphs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adj_graphs])\n\u001b[1;32m    293\u001b[0m masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mlen\u001b[39m(graphs), max_nodes), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, graph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graphs):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 40.2 GiB for an array with shape (73492, 73492) and data type float64"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0953ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msg\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_history(history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sg' is not defined"
     ]
    }
   ],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf0f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
